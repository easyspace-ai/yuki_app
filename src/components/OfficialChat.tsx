'use client';

import {
  Branch,
  BranchMessages,
  BranchNext,
  BranchPage,
  BranchPrevious,
  BranchSelector,
} from '@/components/ai-elements/branch';
import {
  Conversation,
  ConversationContent,
  ConversationScrollButton,
} from '@/components/ai-elements/conversation';
import {
  PromptInput,
  PromptInputActionAddAttachments,
  PromptInputActionMenu,
  PromptInputActionMenuContent,
  PromptInputActionMenuTrigger,
  PromptInputAttachment,
  PromptInputAttachments,
  PromptInputBody,
  PromptInputButton,
  type PromptInputMessage,
  PromptInputModelSelect,
  PromptInputModelSelectContent,
  PromptInputModelSelectItem,
  PromptInputModelSelectTrigger,
  PromptInputModelSelectValue,
  PromptInputSpeechButton,
  PromptInputSubmit,
  PromptInputTextarea,
  PromptInputFooter,
  PromptInputTools,
} from '@/components/ai-elements/prompt-input';
import {
  Message,
  MessageAvatar,
  MessageContent,
} from '@/components/ai-elements/message';
import {
  Reasoning,
  ReasoningContent,
  ReasoningTrigger,
} from '@/components/ai-elements/reasoning';
import { Response } from '@/components/ai-elements/response';
import {
  Source,
  Sources,
  SourcesContent,
  SourcesTrigger,
} from '@/components/ai-elements/sources';
import {
  Suggestion,
  Suggestions,
} from '@/components/ai-elements/suggestion';
import { GlobeIcon } from 'lucide-react';
import { useState, useCallback, useRef } from 'react';
import { toast } from 'sonner';
import type { ToolUIPart } from 'ai';
import { nanoid } from 'nanoid';
import { useModelSettings } from '@/hooks/useModelSettings';
import { getProviderSpec } from '@/lib/providers';

type MessageType = {
  key: string;
  from: 'user' | 'assistant';
  sources?: { href: string; title: string }[];
  versions: {
    id: string;
    content: string;
  }[];
  reasoning?: {
    content: string;
    duration: number;
  };
  tools?: {
    name: string;
    description: string;
    status: ToolUIPart['state'];
    parameters: Record<string, unknown>;
    result: string | undefined;
    error: string | undefined;
  }[];
  avatar: string;
  name: string;
};

const initialMessages: MessageType[] = [
  {
    key: nanoid(),
    from: 'user',
    versions: [
      {
        id: nanoid(),
        content: '‰Ω†Â•ΩÔºÅËØ∑‰ªãÁªç‰∏Ä‰∏ã‰Ω†ÁöÑÂäüËÉΩ„ÄÇ',
      },
    ],
    avatar: 'https://github.com/haydenbleasel.png',
    name: 'Áî®Êà∑',
  },
  {
    key: nanoid(),
    from: 'assistant',
    sources: [
      {
        href: 'https://react.dev/reference/react',
        title: 'React Documentation',
      },
    ],
    versions: [
      {
        id: nanoid(),
        content: `# AI ÂÜô‰ΩúÂä©Êâã

‰Ω†Â•ΩÔºÅÊàëÊòØ‰Ω†ÁöÑ AI ÂÜô‰ΩúÂä©ÊâãÔºå‰∏ìÈó®Â∏ÆÂä©ÊèêÂçáÊñáÊ°£Ë¥®Èáè„ÄÇ

## ÊàëÁöÑÂäüËÉΩ

‚Ä¢ **üìù ‰ºòÂåñÊñáÊú¨Ë°®Ëææ** - ËÆ©ÊñáÂ≠óÊõ¥ÁÆÄÊ¥Å„ÄÅÊµÅÁïÖ„ÄÅ‰∏ì‰∏ö
‚Ä¢ **üéØ Êèê‰æõÂÜô‰ΩúÂª∫ËÆÆ** - Ê†πÊçÆ‰Ω†ÁöÑÈúÄÊ±ÇÁªôÂá∫ÈíàÂØπÊÄßÂª∫ËÆÆ  
‚Ä¢ **üìä ÂàÜÊûêÊñáÊ°£ÁªìÊûÑ** - Â∏Æ‰Ω†Ê¢≥ÁêÜÈÄªËæëÂíåÂ±ÇÊ¨°
‚Ä¢ **‚ú® ÁîüÊàêÂàõÊÑèÂÜÖÂÆπ** - ÊøÄÂèëÁÅµÊÑüÔºå‰∏∞ÂØåÂÜÖÂÆπ

## ‰ΩøÁî®Âª∫ËÆÆ

- ÂèØ‰ª•ÈóÆÊàë‰ªª‰ΩïÂÖ≥‰∫éÂÜô‰ΩúÁöÑÈóÆÈ¢ò
- ÊîØÊåÅ‰∏≠Ëã±ÊñáÂØπËØù
- ÂèØ‰ª•‰∏ä‰º†Êñá‰ª∂ËøõË°åÂàÜÊûê
- ÊîØÊåÅÂ§öÁßç AI Ê®°ÂûãÂàáÊç¢

Êúâ‰ªÄ‰πàÈúÄË¶ÅÂ∏ÆÂä©ÁöÑÂêóÔºü`,
      },
    ],
    avatar: 'https://github.com/openai.png',
    name: 'AI Âä©Êâã',
  },
];

const getModels = (currentSettings: any) => {
  const baseModels = [
    { id: 'gpt-4', name: 'GPT-4' },
    { id: 'gpt-3.5-turbo', name: 'GPT-3.5 Turbo' },
    { id: 'claude-2', name: 'Claude 2' },
    { id: 'claude-instant', name: 'Claude Instant' },
    { id: 'palm-2', name: 'PaLM 2' },
    { id: 'llama-2-70b', name: 'Llama 2 70B' },
    { id: 'llama-2-13b', name: 'Llama 2 13B' },
    { id: 'cohere-command', name: 'Command' },
    { id: 'mistral-7b', name: 'Mistral 7B' },
  ];

  // Ê†πÊçÆÂΩìÂâçÈÖçÁΩÆÊ∑ªÂä†Ëá™ÂÆö‰πâÊ®°ÂûãÈÄâÈ°πÔºå‰ΩøÁî®Êõ¥ÁÆÄÊ¥ÅÁöÑÊòæÁ§∫
  if (currentSettings.provider === 'ollama' && currentSettings.model) {
    const modelName = currentSettings.model.split(':')[0] || 'Ollama';
    return [
      { id: 'ollama', name: modelName },
      ...baseModels
    ];
  }
  
  if (currentSettings.provider === 'siliconflow' && currentSettings.model) {
    const modelName = currentSettings.model.split('/').pop() || 'SiliconFlow';
    return [
      { id: 'siliconflow', name: modelName },
      ...baseModels
    ];
  }

  return baseModels;
};

const suggestions = [
  'Â∏ÆÊàëÂÜô‰∏Ä‰ªΩ‰ºöËÆÆÁ∫™Ë¶Å',
  '‰ºòÂåñËøôÊÆµÊñáÂ≠óÁöÑË°®Ëææ',
  'Ê£ÄÊü•ËØ≠Ê≥ïÂíåÁªìÊûÑ',
  'Êèê‰æõÂÜô‰ΩúÂàõÊÑè',
  'ÂàÜÊûêÊñáÊ°£ÁªìÊûÑ',
  'ÁîüÊàê‰∫ßÂìÅ‰ªãÁªç',
  'ÂÜô‰∏Ä‰ªΩÊäÄÊúØÊñáÊ°£',
  'Âàõ‰ΩúËê•ÈîÄÊñáÊ°à',
];

const mockResponses = [
  "ËøôÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÈóÆÈ¢òÔºÅËÆ©ÊàëÊù•Â∏Æ‰Ω†ÂàÜÊûê‰∏Ä‰∏ã„ÄÇÊ†πÊçÆÊàëÁöÑÁêÜËß£ÔºåËøô‰∏™ÈóÆÈ¢òÊ∂âÂèäÂà∞Âá†‰∏™ÂÖ≥ÈîÆÁÇπÔºåÊàë‰ºöÈÄê‰∏Ä‰∏∫‰Ω†ËØ¶ÁªÜËß£Èáä„ÄÇ",
  "ÊàëÂæà‰πêÊÑè‰∏∫‰Ω†Êèê‰æõÂ∏ÆÂä©„ÄÇ‰ªéÊàëÁöÑËßíÂ∫¶Êù•ÁúãÔºåËøô‰∏™ÈóÆÈ¢òÈúÄË¶Å‰ªéÂ§ö‰∏™ËßíÂ∫¶Êù•ËÄÉËôë„ÄÇËÆ©Êàë‰∏∫‰Ω†Ê¢≥ÁêÜ‰∏Ä‰∏ãÊÄùË∑Ø„ÄÇ",
  "ËøôÊòØ‰∏Ä‰∏™ÂæàÊúâË∂£ÁöÑËØùÈ¢òÔºÅËÆ©ÊàëÊù•‰∏∫‰Ω†ËØ¶ÁªÜËß£Á≠î„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅÁêÜËß£Âü∫Á°ÄÊ¶ÇÂøµÔºåÁÑ∂ÂêéÈÄêÊ≠•Ê∑±ÂÖ•„ÄÇ",
  "Â•ΩÁöÑÔºåÊàëÊù•Â∏Æ‰Ω†Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÊ†πÊçÆÊàëÁöÑÁªèÈ™åÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØÂÖàÂàÜÊûêÁé∞Áä∂ÔºåÁÑ∂ÂêéÂà∂ÂÆöÂÖ∑‰ΩìÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ",
  "ËøôÁ°ÆÂÆûÊòØ‰∏Ä‰∏™ÂÄºÂæóÊ∑±ÂÖ•Êé¢ËÆ®ÁöÑËØùÈ¢ò„ÄÇËÆ©Êàë‰∏∫‰Ω†Êèê‰æõ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂàÜÊûêÂíåÂª∫ËÆÆ„ÄÇ",
];

const OfficialChat = () => {
  const { settings } = useModelSettings();
  const [model, setModel] = useState<string>(() => {
    // Ê†πÊçÆÂΩìÂâçÈÖçÁΩÆÈÄâÊã©ÈªòËÆ§Ê®°Âûã
    if (settings.provider === 'ollama') return 'ollama';
    if (settings.provider === 'siliconflow') return 'siliconflow';
    return 'gpt-4'; // ÈªòËÆ§ GPT-4
  });
  const [text, setText] = useState<string>('');
  const [useWebSearch, setUseWebSearch] = useState<boolean>(false);
  const [status, setStatus] = useState<
    'submitted' | 'streaming' | 'ready' | 'error'
  >('ready');
  const [messages, setMessages] = useState<MessageType[]>(initialMessages);
  const [streamingMessageId, setStreamingMessageId] = useState<string | null>(
    null,
  );
  const shouldCancelRef = useRef<boolean>(false);
  const addMessageTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const textareaRef = useRef<HTMLTextAreaElement>(null);

  const stop = useCallback(() => {
    console.log('Stopping generation...');

    // Set cancellation flag
    shouldCancelRef.current = true;

    // Clear timeout for adding assistant message
    if (addMessageTimeoutRef.current) {
      clearTimeout(addMessageTimeoutRef.current);
      addMessageTimeoutRef.current = null;
    }

    setStatus('ready');
    setStreamingMessageId(null);
  }, []);

  const streamResponse = useCallback(
    async (messageId: string, content: string) => {
      setStatus('streaming');
      setStreamingMessageId(messageId);
      shouldCancelRef.current = false;

      const words = content.split(' ');
      let currentContent = '';

      for (let i = 0; i < words.length; i++) {
        // Check if streaming should be cancelled
        if (shouldCancelRef.current) {
          setStatus('ready');
          setStreamingMessageId(null);
          return;
        }

        currentContent += (i > 0 ? ' ' : '') + words[i];

        setMessages((prev) =>
          prev.map((msg) => {
            if (msg.versions.some((v) => v.id === messageId)) {
              return {
                ...msg,
                versions: msg.versions.map((v) =>
                  v.id === messageId ? { ...v, content: currentContent } : v,
                ),
              };
            }
            return msg;
          }),
        );

        await new Promise((resolve) =>
          setTimeout(resolve, Math.random() * 100 + 50),
        );
      }

      setStatus('ready');
      setStreamingMessageId(null);
    },
    [],
  );

  const addUserMessage = useCallback(
    async (content: string) => {
      const userMessage: MessageType = {
        key: `user-${Date.now()}`,
        from: 'user',
        versions: [
          {
            id: `user-${Date.now()}`,
            content,
          },
        ],
        avatar: 'https://github.com/haydenbleasel.png',
        name: 'Áî®Êà∑',
      };

      setMessages((prev) => [...prev, userMessage]);

      // ÂàõÂª∫Âä©ÊâãÊ∂àÊÅØÂç†‰ΩçÁ¨¶
      const assistantMessageId = `assistant-${Date.now()}`;
      const assistantMessage: MessageType = {
        key: `assistant-${Date.now()}`,
        from: 'assistant',
        versions: [
          {
            id: assistantMessageId,
            content: '',
          },
        ],
        avatar: 'https://github.com/openai.png',
        name: 'AI Âä©Êâã',
      };

      setMessages((prev) => [...prev, assistantMessage]);

      try {
        // Â∞ùËØïË∞ÉÁî®ÁúüÂÆûÊ®°Âûã
        const spec = getProviderSpec(settings.provider);
        if (spec?.chat) {
          setStatus('streaming');
          setStreamingMessageId(assistantMessageId);
          
          const response = await spec.chat(content, {
            baseUrl: settings.baseUrl || '',
            apiToken: settings.apiToken || '',
            model: settings.model || ''
          });
          
          if (response) {
            streamResponse(assistantMessageId, response);
          } else {
            throw new Error('Ê®°ÂûãËøîÂõûÁ©∫ÂìçÂ∫î');
          }
        } else {
          // Â¶ÇÊûúÊ≤°ÊúâÈÖçÁΩÆÁúüÂÆûÊ®°ÂûãÔºå‰ΩøÁî®Ê®°ÊãüÂìçÂ∫î
          const randomResponse = mockResponses[Math.floor(Math.random() * mockResponses.length)];
          streamResponse(assistantMessageId, randomResponse);
        }
      } catch (error: any) {
        console.error('Ê®°ÂûãË∞ÉÁî®Â§±Ë¥•:', error);
        toast.error('Ê®°ÂûãË∞ÉÁî®Â§±Ë¥•', {
          description: error?.message || 'ËØ∑Ê£ÄÊü•Ê®°ÂûãÈÖçÁΩÆ',
        });
        
        // Â§±Ë¥•Êó∂‰ΩøÁî®Ê®°ÊãüÂìçÂ∫î
        const fallbackResponse = `Êä±Ê≠âÔºåÊ®°ÂûãË∞ÉÁî®Â§±Ë¥•Ôºö${error?.message || 'Êú™Áü•ÈîôËØØ'}„ÄÇ\n\nËØ∑Ê£ÄÊü•Ôºö\n‚Ä¢ Ê®°ÂûãÈÖçÁΩÆÊòØÂê¶Ê≠£Á°Æ\n‚Ä¢ ÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏\n‚Ä¢ API ÂØÜÈí•ÊòØÂê¶ÊúâÊïà\n\nÂΩìÂâç‰ΩøÁî®Ê®°ÊãüÂìçÂ∫î„ÄÇ`;
        streamResponse(assistantMessageId, fallbackResponse);
      }
    },
    [streamResponse, settings],
  );

  const handleSubmit = async (message: PromptInputMessage) => {
    // If currently streaming or submitted, stop instead of submitting
    if (status === 'streaming' || status === 'submitted') {
      stop();
      return;
    }

    const hasText = Boolean(message.text);
    const hasAttachments = Boolean(message.files?.length);

    if (!(hasText || hasAttachments)) {
      return;
    }

    setStatus('submitted');

    if (message.files?.length) {
      toast.success('Êñá‰ª∂Â∑≤ÈôÑÂä†', {
        description: `Â∑≤ÈôÑÂä† ${message.files.length} ‰∏™Êñá‰ª∂Âà∞Ê∂àÊÅØ`,
      });
    }

    await addUserMessage(message.text || 'Â∑≤ÂèëÈÄÅÈôÑ‰ª∂');
    setText('');
  };

  const handleSuggestionClick = async (suggestion: string) => {
    setStatus('submitted');
    await addUserMessage(suggestion);
  };

  return (
    <div className="h-full w-full flex flex-col overflow-hidden">
      <div className="flex-1 min-h-0">
        <Conversation className="h-full">
          <ConversationContent>
            {messages.map(({ versions, ...message }) => (
              <Branch defaultBranch={0} key={message.key}>
                <BranchMessages>
                  {versions.map((version) => (
                    <Message
                      from={message.from}
                      key={`${message.key}-${version.id}`}
                    >
                      <div>
                        {message.sources?.length && (
                          <Sources>
                            <SourcesTrigger count={message.sources.length} />
                            <SourcesContent>
                              {message.sources.map((source) => (
                                <Source
                                  href={source.href}
                                  key={source.href}
                                  title={source.title}
                                />
                              ))}
                            </SourcesContent>
                          </Sources>
                        )}
                        {message.reasoning && (
                          <Reasoning duration={message.reasoning.duration}>
                            <ReasoningTrigger />
                            <ReasoningContent>
                              {message.reasoning.content}
                            </ReasoningContent>
                          </Reasoning>
                        )}
                        <MessageContent>
                          <Response>{version.content}</Response>
                        </MessageContent>
                      </div>
                      <MessageAvatar name={message.name} src={message.avatar} />
                    </Message>
                  ))}
                </BranchMessages>
                {versions.length > 1 && (
                  <BranchSelector from={message.from}>
                    <BranchPrevious />
                    <BranchPage />
                    <BranchNext />
                  </BranchSelector>
                )}
              </Branch>
            ))}
          </ConversationContent>
          <ConversationScrollButton />
        </Conversation>
      </div>
      
      <div className="shrink-0 border-t bg-background">
        <div className="grid gap-4 pt-4">
          <Suggestions className="px-4">
            {suggestions.map((suggestion) => (
              <Suggestion
                key={suggestion}
                onClick={() => handleSuggestionClick(suggestion)}
                suggestion={suggestion}
              />
            ))}
          </Suggestions>
          <div className="w-full px-4 pb-4">
            <PromptInput
              className="border border-blue-200 rounded-lg bg-background shadow-sm focus-within:ring-2 focus-within:ring-blue-200/50 focus-within:border-blue-400 transition-all duration-200"
              globalDrop
              multiple
              onSubmit={handleSubmit}
            >
              <PromptInputBody className="p-3">
                <PromptInputAttachments>
                  {(attachment) => <PromptInputAttachment data={attachment} />}
                </PromptInputAttachments>
                <PromptInputTextarea
                  className="min-h-[60px] max-h-[120px] resize-none border-0 bg-transparent outline-none ring-0 focus-visible:ring-0 focus-visible:outline-none placeholder:text-muted-foreground"
                  onChange={(event) => setText(event.target.value)}
                  ref={textareaRef}
                  value={text}
                  placeholder="ËæìÂÖ•Ê∂àÊÅØ... (Shift+Enter Êç¢Ë°åÔºåEnter ÂèëÈÄÅ)"
                />
              </PromptInputBody>
              <PromptInputFooter className="px-3 pb-3 pt-2 border-t border-gray-100">
                <PromptInputTools className="gap-2">
                  <PromptInputActionMenu>
                    <PromptInputActionMenuTrigger />
                    <PromptInputActionMenuContent>
                      <PromptInputActionAddAttachments />
                    </PromptInputActionMenuContent>
                  </PromptInputActionMenu>
                  <PromptInputSpeechButton
                    onTranscriptionChange={setText}
                    textareaRef={textareaRef}
                  />
                  <PromptInputButton
                    onClick={() => setUseWebSearch(!useWebSearch)}
                    variant={useWebSearch ? 'default' : 'ghost'}
                    className="h-8 px-3 text-gray-600 hover:text-gray-900"
                  >
                    <GlobeIcon size={16} />
                    <span>ÊêúÁ¥¢</span>
                  </PromptInputButton>
                  <PromptInputModelSelect onValueChange={setModel} value={model}>
                    <PromptInputModelSelectTrigger className="h-8 px-3 text-gray-600 border-none shadow-none focus:ring-0">
                      <PromptInputModelSelectValue />
                    </PromptInputModelSelectTrigger>
                    <PromptInputModelSelectContent>
                      {getModels(settings).map((model) => (
                        <PromptInputModelSelectItem
                          key={model.id}
                          value={model.id}
                        >
                          {model.name}
                        </PromptInputModelSelectItem>
                      ))}
                    </PromptInputModelSelectContent>
                  </PromptInputModelSelect>
                </PromptInputTools>
                <PromptInputSubmit
                  disabled={(!text.trim() && !status) || status === 'streaming'}
                  status={status}
                  className="h-8 w-8 p-0 bg-blue-600 hover:bg-blue-700 text-white"
                />
              </PromptInputFooter>
            </PromptInput>
          </div>
        </div>
      </div>
    </div>
  );
};

export default OfficialChat;